{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"GAN_workshop.ipynb","provenance":[{"file_id":"14ywiqCoAUBp_viDzUttwoYW1G6ThGZtO","timestamp":1595818562236}],"private_outputs":true,"collapsed_sections":[],"authorship_tag":"ABX9TyNg44NzgyS/7FPpXW5XErvY"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"XiPEfzPA4c-s","colab_type":"text"},"source":["### **Develop a GAN to Generate Small Photos**"]},{"cell_type":"markdown","metadata":{"id":"ceRDQhXk4tyN","colab_type":"text"},"source":["This tutorial includes the following steps:\n","\n","    * Obtain CIFAR-10 Small Object Photograph Dataset\n","    * Define and Train the Discriminator Model\n","    * Define and Use the Generator Model\n","    * Train the Generator Model\n","    * Evaluate GAN Model Performance\n","    * Use the Final Generator Model to Generate Images\n"]},{"cell_type":"markdown","metadata":{"id":"3KiiVodKdrLN","colab_type":"text"},"source":["#### **Mount Google Drive**"]},{"cell_type":"code","metadata":{"id":"AAXbjMoWeUPo","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yGHjOVZceUOW","colab_type":"code","colab":{}},"source":["import os\n","# change the current dictory to the folder where you save the .h5 files\n","# For example, \n","#os.chdir('/content/drive/My Drive/Colab Notebooks/GANs')\n","os.chdir('/content/drive/My Drive/') \n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7dPfdHVC5Y4J","colab_type":"text"},"source":["##### [CIFAR-10 ](https://www.cs.toronto.edu/~kriz/cifar.html)dataset was developed at the CIFAR institute, which is comprised of 60,000 32×32 pixel color photographs of objects from 10 classes, such as frogs, birds, cats, ships, airplanes, etc.\n","\n","The cell below loads the dataset and summarizes the shape of the loaded dataset."]},{"cell_type":"code","metadata":{"id":"r56SRFW1hqF4","colab_type":"code","colab":{}},"source":["# example of loading and plotting the cifar10 dataset\n","from keras.datasets.cifar10 import load_data\n","import matplotlib.pyplot as plt\n","\n","# load the images into memory\n","(trainX, trainy), (testX, testy) = load_data()\n","\n","# summarize the shape of the dataset\n","print('Train', trainX.shape, trainy.shape)\n","print('Test', testX.shape, testy.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YEgCSq_Y65CM","colab_type":"text"},"source":["We can see that there are 50K examples in the training set and 10K in the test set and that each image is a square of 32 by 32 pixels.\n","\n","The images are color with the object centered in the middle of the frame.  We can plot some of the images from the training dataset with the matplotlib library using the imshow() function.\n","\n","below we plot the last 25 images from the training dataset in a 5 by 5 montage."]},{"cell_type":"code","metadata":{"id":"WvLBuqVqh33s","colab_type":"code","colab":{}},"source":["# plot images from the training dataset\n","fig = plt.figure(figsize=(8,8))\n","for i in range(-25, 0):\n","\t# define subplot\n","\tax = fig.add_subplot(5,5, 26+i)\n"," \n","\t# turn off axis\n","\tax.xaxis.set_visible(False)\n","\tax.yaxis.set_visible(False)\n"," \n","\t# plot raw pixel data\n","\tax.imshow(trainX[i])\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d7nwNrDaA73f","colab_type":"text"},"source":["#### **First, we define the discriminator model.**\n","The model takes a sample image from our dataset as input and outputs a classification prediction as either real or fake. This is a binary classification problem.\n","\n","    Inputs: Image with three color channel and 32×32 pixels in size.\n","    Outputs: Binary classification, likelihood the sample is real (or fake).\n","\n","The `define_discriminator()` function below defines the discriminator model and parametrizes the size of the input image."]},{"cell_type":"code","metadata":{"id":"a-c5fKxpi3bi","colab_type":"code","colab":{}},"source":["# example of defining the discriminator model\n","from numpy import expand_dims\n","from numpy import zeros\n","from numpy import ones\n","from numpy import vstack\n","from numpy.random import randn\n","from numpy.random import randint\n","from keras.datasets.cifar10 import load_data\n","from keras.optimizers import Adam\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import Reshape\n","from keras.layers import Flatten\n","from keras.layers import Conv2D\n","from keras.layers import Conv2DTranspose\n","from keras.layers import LeakyReLU\n","from keras.layers import Dropout\n","from matplotlib import pyplot\n","from keras.utils.vis_utils import plot_model\n","from keras.models import load_model\n"," \n","# define the standalone discriminator model\n","def define_discriminator(in_shape=(32,32,3)):\n","\tmodel = Sequential()\n","\t# normal\n","\tmodel.add(Conv2D(64, (3,3), padding='same', input_shape=in_shape))\n","\tmodel.add(LeakyReLU(alpha=0.2))\n","\t# downsample\n","\tmodel.add(Conv2D(128, (3,3), strides=(2,2), padding='same'))\n","\tmodel.add(LeakyReLU(alpha=0.2))\n","\t# downsample\n","\tmodel.add(Conv2D(128, (3,3), strides=(2,2), padding='same'))\n","\tmodel.add(LeakyReLU(alpha=0.2))\n","\t# downsample\n","\tmodel.add(Conv2D(256, (3,3), strides=(2,2), padding='same'))\n","\tmodel.add(LeakyReLU(alpha=0.2))\n","\t# classifier\n","\tmodel.add(Flatten())\n","\tmodel.add(Dropout(0.3))\n","\tmodel.add(Dense(1, activation='sigmoid'))\n","\t# compile model\n","\topt = Adam(lr=0.0002, beta_1=0.5)\n","\tmodel.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n","\treturn model\n","\n","# define model\n","model = define_discriminator()\n","# summarize the model\n","model.summary()\n","# plot the model\n","plot_model(model, to_file='discriminator_plot.png', show_shapes=True, show_layer_names=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GUUtZk3pCoUY","colab_type":"text"},"source":["We could start training this model now with real examples with a class label of one and randomly generate samples with a class label of zero.\n","We use the cifar.load_data() function to load the CIFAR-10 dataset and just use the input part of the training dataset as the real images. Scale the pixel values from the range of unsigned integers in [0,255] to the normalized range of [-1,1]."]},{"cell_type":"code","metadata":{"id":"dEGyhHY1jdrD","colab_type":"code","colab":{}},"source":["# load and prepare cifar10 training images\n","def load_real_samples():\n","\t# load cifar10 dataset\n","\t(trainX, _), (_, _) = load_data()\n","\t# convert from unsigned ints to floats\n","\tX = trainX.astype('float32')\n","\t# scale from [0,255] to [-1,1]\n","\tX = (X - 127.5) / 127.5\n","\treturn X"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"H5XhFB0ODxAs","colab_type":"text"},"source":["The model will be updated in batches. On training an epoch is defined as one passes through the entire training cohort.<br><br> \n","Training via stochastic gradient descent requires that the training dataset be shuffled prior to each epoch. A simpler approach is to select random samples of images from the training dataset.<br>\n","The `generate_real_samples()` function below will take the training dataset as an argument and will select a random subsample of images; it will also return class labels for the sample, specifically a class label of 1, to indicate real images.\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"c0s7n6rkkKkK","colab_type":"code","colab":{}},"source":["# select real samples\n","def generate_real_samples(dataset, n_samples):\n","\t# choose random instances\n","\tix = randint(0, dataset.shape[0], n_samples)\n","\t# retrieve selected images\n","\tX = dataset[ix]\n","\t# generate 'real' class labels (1)\n","\ty = ones((n_samples, 1))\n","\treturn X, y"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MnDSBCbZFrEM","colab_type":"text"},"source":["Next, we need a source of fake images.<br>\n","The `generate_fake_samples()` function below implements this behavior and generates images of random pixel values and their associated class label of 0, for fake."]},{"cell_type":"code","metadata":{"id":"wgj08qvzkfsT","colab_type":"code","colab":{}},"source":["# use the generator to generate n fake examples, with class labels\n","def generate_fake_samples(g_model, latent_dim, n_samples):\n","\t# generate points in latent space\n","\tx_input = generate_latent_points(latent_dim, n_samples)\n","\t# predict outputs\n","\tX = g_model.predict(x_input)\n","\t# create 'fake' class labels (0)\n","\ty = zeros((n_samples, 1))\n","\treturn X, y"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GPdXFaN4hCrD","colab_type":"text"},"source":["#### **Secondly, define and Use the Generator Model**\n","The generator model is responsible for creating new, fake, but plausible small photographs of objects.\n","\n","It does this by taking a point from the latent space as input and outputting a square color image."]},{"cell_type":"markdown","metadata":{"id":"AGtWJLJViSBa","colab_type":"text"},"source":["The latent space is an arbitrarily defined vector space of Gaussian-distributed values, e.g. 100 dimensions. It has no meaning, but by drawing points from this space randomly and providing them to the generator model during training, the generator model will assign meaning to the latent points and, in turn, the latent space, until, at the end of training, the latent vector space represents a compressed representation of the output space, CIFAR-10 images, that only the generator knows how to turn into plausible CIFAR-10 images.\n","\n","    Inputs: Point in latent space, e.g. a 100-element vector of Gaussian random numbers.\n","    Outputs: Two-dimensional square color image (3 channels) of 32 x 32 pixels with pixel values in [-1,1].\n","\n","we use the LeakyReLU with a default slope of 0.2, reported as a best practice when training GAN models."]},{"cell_type":"code","metadata":{"id":"2dyfHE8EliuR","colab_type":"code","colab":{}},"source":["# define the standalone generator model\n","def define_generator(latent_dim):\n","\tmodel = Sequential()\n","\t# foundation for 4x4 image\n","\tn_nodes = 256 * 4 * 4\n","\tmodel.add(Dense(n_nodes, input_dim=latent_dim))\n","\tmodel.add(LeakyReLU(alpha=0.2))\n","\tmodel.add(Reshape((4, 4, 256)))\n","\t# upsample to 8x8\n","\tmodel.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n","\tmodel.add(LeakyReLU(alpha=0.2))\n","\t# upsample to 16x16\n","\tmodel.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n","\tmodel.add(LeakyReLU(alpha=0.2))\n","\t# upsample to 32x32\n","\tmodel.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n","\tmodel.add(LeakyReLU(alpha=0.2))\n","\t# output layer\n","\tmodel.add(Conv2D(3, (3,3), activation='tanh', padding='same'))\n","\treturn model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Jy7fBYpzjP-f","colab_type":"text"},"source":["The `define_generator()` function below implements this and defines the generator model.\n","\n","**Note:** the generator model is not compiled and does not specify a loss function or optimization algorithm. This is because the generator is not trained directly. \n","\n","Now summarize the model to help better understand the input and output shapes."]},{"cell_type":"code","metadata":{"id":"KgB6YWRznWta","colab_type":"code","colab":{}},"source":["# define the size of the latent space\n","latent_dim = 100\n","# define the generator model\n","model = define_generator(latent_dim)\n","# summarize the model\n","model.summary()\n","# plot the model\n","plot_model(model, to_file='generator_plot.png', show_shapes=True, show_layer_names=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AEYIgYucj7hg","colab_type":"text"},"source":["To generate new points in the latent space, We can call the `randn()` NumPy function for generating arrays of random numbers drawn from a standard Gaussian."]},{"cell_type":"code","metadata":{"id":"yes4GGlungGE","colab_type":"code","colab":{}},"source":["# generate points in latent space as input for the generator\n","def generate_latent_points(latent_dim, n_samples):\n","\t# generate points in the latent space\n","\tx_input = randn(latent_dim * n_samples)\n","\t# reshape into a batch of inputs for the network\n","\tx_input = x_input.reshape(n_samples, latent_dim)\n","\treturn x_input"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wd5lIFa5kTbP","colab_type":"text"},"source":["We can now define the `generate_fake_samples()` function by taking the generator model as an argument and use it to generate the desired number of samples by first calling the `generate_latent_points()` function to generate the required number of points in latent space as input to the model."]},{"cell_type":"code","metadata":{"id":"tTgm4wKko2oH","colab_type":"code","colab":{}},"source":["# use the generator to generate n fake examples, with class labels\n","def generate_fake_samples(g_model, latent_dim, n_samples):\n","\t# generate points in latent space\n","\tx_input = generate_latent_points(latent_dim, n_samples)\n","\t# predict outputs\n","\tX = g_model.predict(x_input)\n","\t# create 'fake' class labels (0)\n","\ty = zeros((n_samples, 1))\n","\treturn X, y"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IGBHhrmbllZs","colab_type":"text"},"source":["Running the example generates 25 examples of fake CIFAR-10 images and visualizes them on a single plot of 5 by 5 images.\n","\n","As the model is not trained, the generated images are completely random pixel values in [-1, 1], rescaled to [0, 1]. As we might expect, the images look like a mess of gray."]},{"cell_type":"code","metadata":{"id":"2gLni0SAo5Zw","colab_type":"code","colab":{}},"source":["# generate samples\n","n_samples = 25\n","X, _ = generate_fake_samples(model, latent_dim, n_samples)\n","# scale pixel values from [-1,1] to [0,1]\n","X = (X + 1) / 2.0\n","# plot the generated samples\n","fig = plt.figure(figsize=(8,8))\n","for i in range(n_samples):\n","\t# define subplot\n","\tax = fig.add_subplot(5, 5, i+1)\n"," \n","\t# turn off axis labels\n","\tax.xaxis.set_visible(False)\n","\tax.yaxis.set_visible(False)\n"," \n","\t# plot single image\n","\tax.imshow(X[i])\n"," \n","# show the figure\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KiTfDByvm3hP","colab_type":"text"},"source":["#### **Train the Generator Model**\n","The weights in the generator model are updated based on the performance of the discriminator model.\n","\n","When the discriminator is good at detecting fake samples, the generator is updated more, and when the discriminator model is relatively poor or confused when detecting fake samples, the generator model is updated less.\n","\n","This defines the zero-sum or adversarial relationship between these two models.<br>\n","One of the simplest approaches is to create a new model that combines the generator and discriminator models.  Therefore, the generator receives as input random points in the latent space and generates samples that are fed into the discriminator model directly, classified, and the output of this larger model can be used to update the model weights of the generator.\n"]},{"cell_type":"markdown","metadata":{"id":"sGefKoSwpzy-","colab_type":"text"},"source":["Only the discriminator is concerned with distinguishing between real and fake examples, therefore the discriminator model can be trained in a standalone manner on examples of each, as we did in the section on the discriminator model above.\n","\n","The generator model is only concerned with the discriminator’s performance on fake examples. Therefore, we will mark all of the layers in the discriminator as not trainable when it is part of the GAN model so that they can not be updated and overtrained on fake examples."]},{"cell_type":"markdown","metadata":{"id":"CQkNROo4rBTH","colab_type":"text"},"source":["We can imagine that the discriminator will then classify the generated samples as not real (class 0) or a low probability of being real (0.3 or 0.5). The backpropagation process used to update the model weights will see this as a large error and will update the model weights (i.e. only the weights in the generator) to correct for this error, in turn making the generator better at generating good fake samples.\n","\n","    Inputs: Point in latent space, e.g. a 100-element vector of Gaussian random numbers.\n","    Outputs: Binary classification, likelihood the sample is real (or fake).\n","\n","The `define_gan()` function below takes as arguments the already-defined generator and discriminator models and creates the new, logical third model subsuming these two models. The weights in the discriminator are marked as not trainable, which only affects the weights as seen by the GAN model and not the standalone discriminator model.\n","\n","The GAN model then uses the same binary cross entropy loss function as the discriminator and the efficient Adam version of stochastic gradient descent with the learning rate of 0.0002 and momentum of 0.5, recommended when training deep convolutional GANs."]},{"cell_type":"code","metadata":{"id":"oxhWUhsDo__5","colab_type":"code","colab":{}},"source":["# define the combined generator and discriminator model, for updating the generator\n","def define_gan(g_model, d_model):\n","\t# make weights in the discriminator not trainable\n","\td_model.trainable = False\n","\t# connect them\n","\tmodel = Sequential()\n","\t# add generator\n","\tmodel.add(g_model)\n","\t# add the discriminator\n","\tmodel.add(d_model)\n","\t# compile model\n","\topt = Adam(lr=0.0002, beta_1=0.5)\n","\tmodel.compile(loss='binary_crossentropy', optimizer=opt)\n","\treturn model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ufpNSN9QqTgD","colab_type":"text"},"source":["The trainable property impacts the model after it is compiled. The discriminator model was compiled with trainable layers, therefore the model weights in those layers will be updated when the standalone model is updated via calls to the `train_on_batch()` function.\n","\n","The discriminator model was then marked as not trainable, added to the GAN model, and compiled. In this model, the model weights of the discriminator model are not trainable and cannot be changed when the GAN model is updated via calls to the `train_on_batch()` function. This change in the trainable property does not impact the training of the standalone discriminator model."]},{"cell_type":"markdown","metadata":{"id":"Ot_UJPNEtT3M","colab_type":"text"},"source":["We first update the discriminator model with real and fake samples, then update the generator via the composite model. <br>\n","A few things to note in this model training function.\n","First, the number of batches within an epoch is defined by how many times the batch size divides into the training dataset.  The discriminator model is updated twice per batch, once with real samples and once with fake samples, which is a best practice as opposed to combining the samples and performing a single update. Last, Finally, the loss is reported in each batch. <br>\n","\n","It is critical to keep an eye on the loss over batches. The reason for this is that a crash in the discriminator loss indicates that the generator model has started generating rubbish examples that the discriminator can easily discriminate.<br>\n","\n","Monitor the discriminator loss and expect it to hover around 0.5 to 0.8 per batch. The generator loss is less critical and may hover between 0.5 and 2 or higher. \n"]},{"cell_type":"code","metadata":{"id":"2GBPY8gIrcOb","colab_type":"code","colab":{}},"source":["# train the generator and discriminator\n","def train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=200, n_batch=128):\n","\tbat_per_epo = int(dataset.shape[0] / n_batch)\n","\thalf_batch = int(n_batch / 2)\n","\t# manually enumerate epochs\n","\tfor i in range(n_epochs):\n","\t\t# enumerate batches over the training set\n","\t\tfor j in range(bat_per_epo):\n","\t\t\t# get randomly selected 'real' samples\n","\t\t\tX_real, y_real = generate_real_samples(dataset, half_batch)\n","\t\t\t# update discriminator model weights\n","\t\t\td_loss1, _ = d_model.train_on_batch(X_real, y_real)\n","\t\t\t# generate 'fake' examples\n","\t\t\tX_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n","\t\t\t# update discriminator model weights\n","\t\t\td_loss2, _ = d_model.train_on_batch(X_fake, y_fake)\n","\t\t\t# prepare points in latent space as input for the generator\n","\t\t\tX_gan = generate_latent_points(latent_dim, n_batch)\n","\t\t\t# create inverted labels for the fake samples\n","\t\t\ty_gan = ones((n_batch, 1))\n","\t\t\t# update the generator via the discriminator's error\n","\t\t\tg_loss = gan_model.train_on_batch(X_gan, y_gan)\n","\t\t\t# summarize loss on this batch\n","\t\t\tif (j+1) % 30 == 0:\n","\t\t\t\tprint('>%d, %d/%d, d1=%.3f, d2=%.3f g=%.3f' %\n","\t\t\t\t(i+1, j+1, bat_per_epo, d_loss1, d_loss2, g_loss))\n","\t\t# evaluate the model performance, sometimes\n","\t\tif (i+1) % 10 == 0:\n","\t\t\tsummarize_performance(i, g_model, d_model, dataset, latent_dim)\n"," "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kneH_KL_vXiL","colab_type":"text"},"source":["#### **Evaluate GAN Model Performance**\n","There are no objective ways to evaluate the performance of a GAN model in general, which means, we cannot calculate this objective error score for generated images.<br>\n","\n","Instead, images must be subjectively evaluated for quality by a human operator. This means that we cannot know when to stop training without looking at examples of generated images. In turn, the adversarial nature of the training process means that the generator is changing after every batch, meaning that once “good enough” images can be generated, the subjective quality of the images may then begin to vary, improve, or even degrade with subsequent updates."]},{"cell_type":"markdown","metadata":{"id":"8fLBKSJZgkBa","colab_type":"text"},"source":["There are three ways to handle this complex training situation.\n","\n","    Periodically evaluate the classification accuracy of the discriminator on real and fake images.\n","    Periodically generate many images and save them to file for subjective review.\n","    Periodically save the generator model.\n","All three of these actions can be performed at the same time for a given training epoch, such as every 10 training epochs. The result will be a saved generator model for which we have a way of subjectively assessing the quality of its output and objectively knowing how well the discriminator was fooled at the time the model was saved."]},{"cell_type":"markdown","metadata":{"id":"ewieRP7uhiV5","colab_type":"text"},"source":["First, we can define a function called `summarize_performance()` that will summarize the performance of the discriminator model. It does this by retrieving a sample of real CIFAR-10 images, as well as generating the same number of fake CIFAR-10 images with the generator model, then evaluating the classification accuracy of the discriminator model on each sample, and reporting these scores.<br>\n","\n","This function can be called from the `train()` function based on the current epoch number, such as every 10 epochs.\n","\n","Next, we update the `summarize_performance()` function to both save the model and to create and save a plot generated examples. The generator model can be saved by calling the save() function on the generator model and providing a unique filename based on the training epoch number."]},{"cell_type":"code","metadata":{"id":"BqpMH_uQs4kB","colab_type":"code","colab":{}},"source":["# evaluate the discriminator, plot generated images, save generator model\n","def summarize_performance(epoch, g_model, d_model, dataset, latent_dim, n_samples=150):\n","\t# prepare real samples\n","\tX_real, y_real = generate_real_samples(dataset, n_samples)\n","\t# evaluate discriminator on real examples\n","\t_, acc_real = d_model.evaluate(X_real, y_real, verbose=0)\n","\t# prepare fake examples\n","\tx_fake, y_fake = generate_fake_samples(g_model, latent_dim, n_samples)\n","\t# evaluate discriminator on fake examples\n","\t_, acc_fake = d_model.evaluate(x_fake, y_fake, verbose=0)\n","\t# summarize discriminator performance\n","\tprint('>Accuracy real: %.0f%%, fake: %.0f%%' % (acc_real*100, acc_fake*100))\n","\t# save plot\n","\tsave_plot(x_fake, epoch)\n","\t# save the discriminator and generator model tile files\n","\td_filename = 'discriminator_model_%03d.h5' % (epoch+1)\n","\tg_filename = 'generator_model_%03d.h5' % (epoch+1)\n","\td_model.save(d_filename)\n","\tg_model.save(g_filename)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CT6e9VBJijaK","colab_type":"text"},"source":["We develop a function to create a plot of the generated samples."]},{"cell_type":"code","metadata":{"id":"mTiy3qKkrgWM","colab_type":"code","colab":{}},"source":["# create and save a plot of generated images\n","def save_plot(examples, epoch, n=5):\n","\t# scale from [-1,1] to [0,1]\n","\texamples = (examples + 1) / 2.0\n","\tfig = plt.figure(figsize=(8,8))\n","\t# plot images\n","\tfor i in range(n * n):\n","\t\t# define subplot\n","\t\tax = fig.add_subplot(n, n, i+1)\n","\t\t# turn off axis\n","\t\tax.xaxis.set_visible(False)\n","\t\tax.yaxis.set_visible(False)\n","\t\t# plot raw pixel data\n","\t\tax.imshow(examples[i])\n","\t# save plot to file\n","\tfilename = 'generated_plot_e%03d.png' % (epoch+1)\n","\tplt.savefig(filename)\n","\tplt.close()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8Q-GxyoCkqvi","colab_type":"text"},"source":["The model performance is reported every batch, including the loss of both the discriminative (d) and generative (g) models.<br>\n","\n","In this case, the loss remains stable over the course of training. The discriminator loss on the real and generated examples sits around 0.5, whereas the loss for the generator trained via the discriminator sits around 1.5 for much of the training process."]},{"cell_type":"code","metadata":{"id":"p6bgbxD7s-Ai","colab_type":"code","colab":{}},"source":["# size of the latent space\n","latent_dim = 100\n","# create the discriminator\n","d_model = define_discriminator()\n","# create the generator\n","g_model = define_generator(latent_dim)\n","# create the gan\n","gan_model = define_gan(g_model, d_model)\n","# load image data\n","dataset = load_real_samples()\n","# train model\n","train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=10)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rA50H5yuNGz7","colab_type":"text"},"source":["`However, training more than 100 epochs will take too long to complete it. Therefore, loading the models saved after training for 20 epochs, for instance, will save some time. `\n","\n","##### **First, your task is to modify the `train()` function to load the saved `g_model` and `d_model` and train the models for another 10 epochs.**<br>  **Note:** `train()` keeps all the features <br>\n","**Hint:** use `load_model(filename)` to load a model\n"]},{"cell_type":"code","metadata":{"id":"aQXJ709NFUi7","colab_type":"code","colab":{}},"source":["### modification\n","# train the generator and discriminator\n","from keras.models import load_model\n","\n","pass"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MR2lu3kwQX6B","colab_type":"text"},"source":["##### **Second, use the saved models (list below) as the auguments of the modifed `train()` function for training:**<br>\n","'generator_model_020.h5',<br>\n","'discriminator_model_020.h5'\n"]},{"cell_type":"code","metadata":{"id":"X8d7yOJ-EuYS","colab_type":"code","colab":{}},"source":["# size of the latent space\n","latent_dim = 100\n","dataset = load_real_samples()\n","# train model\n","pass"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4QVqt5nYVMJr","colab_type":"text"},"source":["##### **Third, use the saved models (list below) as the auguments of the modifed `train()` function for training:**<br>\n","'generator_model_050.h5',<br>\n","'discriminator_model_050.h5'<br>\n","**After that\n","use the saved models (list below) as the auguments of the modifed `train()` function for training:**<br>\n","'generator_model_100.h5',<br>\n","'discriminator_model_100.h5'<br>"]},{"cell_type":"code","metadata":{"id":"lnOjF2y7r8de","colab_type":"code","colab":{}},"source":["# size of the latent space\n","latent_dim = 100\n","dataset = load_real_samples()\n","# train model\n","pass\n","pass"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hXEiyyaJxt2j","colab_type":"text"},"source":["#### **Use the Final Generator Model to Generate Images**\n","This involves first loading the model from file, then using it to generate images. The generation of each image requires a point in the latent space as input."]},{"cell_type":"code","metadata":{"id":"K2Zuq3BEtGkD","colab_type":"code","colab":{}},"source":["# example of loading the generator model and generating images\n","from keras.models import load_model\n","from numpy.random import randn\n","import matplotlib.pyplot as plt\n","\n","# generate points in latent space as input for the generator\n","def generate_latent_points(latent_dim, n_samples):\n","\t# generate points in the latent space\n","\tx_input = randn(latent_dim * n_samples)\n","\t# reshape into a batch of inputs for the network\n","\tx_input = x_input.reshape(n_samples, latent_dim)\n","\treturn x_input\n","\n","# plot the generated images\n","def create_plot(examples, n):\n","  # plot images\n","  fig = plt.figure(figsize=(8,8))\n","  for i in range(n * n):\n","\t\t# define subplot\n","    ax = fig.add_subplot(n, n, 1 + i)\n","\t\t# turn off axis\n","    ax.xaxis.set_visible(False)\n","    ax.yaxis.set_visible(False)\n","\t\t# plot raw pixel data\n","    ax.imshow(examples[i, :, :])\n","  plt.show()\n","\n","# load model\n","model = load_model('generator_model_200.h5')\n","# generate images\n","latent_points = generate_latent_points(100, 100)\n","# generate images\n","X = model.predict(latent_points)\n","# scale from [-1,1] to [0,1]\n","X = (X + 1) / 2.0\n","# plot the result\n","create_plot(X, 10)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TxDbvvCezPYw","colab_type":"text"},"source":["#### **Further exploration**\n","\n","* **Change Latent Space.** Update the example to use a larger or smaller latent space and compare the quality of the results and speed of training.\n","* **Batch Normalization.** Update the discriminator and/or the generator to make use of batch normalization, recommended for DCGAN models.\n","* **Label Smoothing.** Update the example to use one-sided label smoothing when training the discriminator, specifically change the target label of real examples from 1.0 to 0.9 and add random noise, then review the effects on image quality and speed of training.\n","* **Model Configuration.** Update the model configuration to use deeper or more shallow discriminator and/or generator models, perhaps experiment with the UpSampling2D layers in the generator.\n","\n","\n"]}]}